{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a4d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8ce2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1020b825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c2c5f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[7345])\n",
    "plt.imshow(x_train[7345]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6dc4642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[7345].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481065f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2262d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[7345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f113025",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ae27ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 32)        4736      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 32)          25632     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 6, 32)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 2, 2, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,964\n",
      "Trainable params: 156,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "## 7x7 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (7, 7), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 3x3 convolution with 1x1 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (3, 3), strides = (1,1)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f83cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 [==============================] - 18s 22ms/step - loss: 4.2777 - accuracy: 0.0472 - val_loss: 3.9762 - val_accuracy: 0.0967\n",
      "Epoch 2/15\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 3.8717 - accuracy: 0.1083 - val_loss: 3.7006 - val_accuracy: 0.1446\n",
      "Epoch 3/15\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 3.6618 - accuracy: 0.1374 - val_loss: 3.4370 - val_accuracy: 0.1876\n",
      "Epoch 4/15\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 3.5149 - accuracy: 0.1631 - val_loss: 3.4677 - val_accuracy: 0.1814\n",
      "Epoch 5/15\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 3.4134 - accuracy: 0.1826 - val_loss: 3.2613 - val_accuracy: 0.2146\n",
      "Epoch 6/15\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 3.3371 - accuracy: 0.1959 - val_loss: 3.2753 - val_accuracy: 0.2133\n",
      "Epoch 7/15\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 3.2806 - accuracy: 0.2061 - val_loss: 3.2826 - val_accuracy: 0.2099\n",
      "Epoch 8/15\n",
      "782/782 [==============================] - 20s 25ms/step - loss: 3.2217 - accuracy: 0.2159 - val_loss: 3.1139 - val_accuracy: 0.2461\n",
      "Epoch 9/15\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 3.1873 - accuracy: 0.2234 - val_loss: 3.1662 - val_accuracy: 0.2381\n",
      "Epoch 10/15\n",
      "782/782 [==============================] - 21s 26ms/step - loss: 3.1421 - accuracy: 0.2325 - val_loss: 3.0436 - val_accuracy: 0.2598\n",
      "Epoch 11/15\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.1041 - accuracy: 0.2380 - val_loss: 3.0366 - val_accuracy: 0.2598\n",
      "Epoch 12/15\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 3.0771 - accuracy: 0.2455 - val_loss: 3.0301 - val_accuracy: 0.2656\n",
      "Epoch 13/15\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 3.0482 - accuracy: 0.2509 - val_loss: 2.9706 - val_accuracy: 0.2813\n",
      "Epoch 14/15\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 3.0252 - accuracy: 0.2533 - val_loss: 3.0106 - val_accuracy: 0.2731\n",
      "Epoch 15/15\n",
      "782/782 [==============================] - 19s 25ms/step - loss: 2.9993 - accuracy: 0.2593 - val_loss: 3.0610 - val_accuracy: 0.2567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2104c51a6d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de2e4b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(32, (3, 3)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Conv2D(64, (3, 3)))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes))\n",
    "model_2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a161882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 13, 13, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1180160   \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               51300     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,297,028\n",
      "Trainable params: 1,297,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634e3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt_2 = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt_2,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7766a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 89s 112ms/step - loss: 4.0689 - accuracy: 0.0801 - val_loss: 3.8412 - val_accuracy: 0.1178\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 3.4627 - accuracy: 0.1751 - val_loss: 3.2275 - val_accuracy: 0.2305\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 87s 111ms/step - loss: 3.1595 - accuracy: 0.2329 - val_loss: 2.9335 - val_accuracy: 0.2769\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 90s 115ms/step - loss: 2.9418 - accuracy: 0.2733 - val_loss: 2.9375 - val_accuracy: 0.2849\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 85s 109ms/step - loss: 2.7816 - accuracy: 0.3069 - val_loss: 2.6194 - val_accuracy: 0.3429\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 86s 109ms/step - loss: 2.6349 - accuracy: 0.3352 - val_loss: 2.5702 - val_accuracy: 0.3516\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 2.5219 - accuracy: 0.3585 - val_loss: 2.6720 - val_accuracy: 0.3361\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 2.4316 - accuracy: 0.3772 - val_loss: 2.5106 - val_accuracy: 0.3702\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 2.3553 - accuracy: 0.3948 - val_loss: 2.3731 - val_accuracy: 0.3968\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 88s 113ms/step - loss: 2.2792 - accuracy: 0.4121 - val_loss: 2.3898 - val_accuracy: 0.3953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2104e0729d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c1d9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ResnetBlock(Model):\n",
    "    \"\"\"\n",
    "    A standard resnet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, down_sample=False):\n",
    "        \"\"\"\n",
    "        channels: same as number of convolution kernels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.__channels = channels\n",
    "        self.__down_sample = down_sample\n",
    "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
    "\n",
    "        KERNEL_SIZE = (3, 3)\n",
    "       \n",
    "        INIT_SCHEME = \"he_normal\"\n",
    "\n",
    "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_2 = BatchNormalization()\n",
    "        self.merge = Add()\n",
    "\n",
    "        if self.__down_sample:\n",
    "            \n",
    "            self.res_conv = Conv2D(\n",
    "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
    "            self.res_bn = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        if self.__down_sample:\n",
    "            res = self.res_conv(res)\n",
    "            res = self.res_bn(res)\n",
    "\n",
    "        \n",
    "        x = self.merge([x, res])\n",
    "        out = tf.nn.relu(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(Model):\n",
    "\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = BatchNormalization()\n",
    "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_4_2 = ResnetBlock(512)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.conv_1(inputs)\n",
    "        out = self.init_bn(out)\n",
    "        out = tf.nn.relu(out)\n",
    "        out = self.pool_2(out)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "            out = res_block(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69e807fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net18_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          multiple                  9472      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  multiple                 256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  multiple                 0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " resnet_block_8 (ResnetBlock  multiple                 74368     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_9 (ResnetBlock  multiple                 74368     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_10 (ResnetBloc  multiple                 231296    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_11 (ResnetBloc  multiple                 296192    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_12 (ResnetBloc  multiple                 921344    \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_13 (ResnetBloc  multiple                 1182208   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_14 (ResnetBloc  multiple                 3677696   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " resnet_block_15 (ResnetBloc  multiple                 4723712   \n",
      " k)                                                              \n",
      "                                                                 \n",
      " global_average_pooling2d_1   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,242,212\n",
      "Trainable params: 11,232,612\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(100)\n",
    "model.build(input_shape = (None,32,32,3))\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5534a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_3 = keras.optimizers.RMSprop(lr=0.0005)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt_3,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "279397cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 1031s 1s/step - loss: 3.6367 - accuracy: 0.1615 - val_loss: 5.6882 - val_accuracy: 0.1065\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 982s 1s/step - loss: 2.8267 - accuracy: 0.2930 - val_loss: 3.8052 - val_accuracy: 0.1918\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 986s 1s/step - loss: 2.4114 - accuracy: 0.3784 - val_loss: 4.0806 - val_accuracy: 0.1969\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 1013s 1s/step - loss: 2.0752 - accuracy: 0.4475 - val_loss: 2.9813 - val_accuracy: 0.2982\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 1024s 1s/step - loss: 1.7681 - accuracy: 0.5178 - val_loss: 4.8228 - val_accuracy: 0.1867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2108cc341c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=5,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe961f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
